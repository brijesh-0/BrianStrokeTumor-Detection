# -*- coding: utf-8 -*-
"""CNN_brain.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hDFzSouQMHqaFaLTkl8xSkWLyV_CXU0e
"""

from google.colab import drive
import os
import zipfile
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense,Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.regularizers import l2
import cv2
import numpy as np
from sklearn.preprocessing import LabelEncoder


drive.mount('/content/drive')

zip_file_path = '/content/drive/MyDrive/Brain_Stroke_CT-SCAN_image 2.zip'

unzip_dir = '/content/'
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(unzip_dir)

data_dir = os.path.join(unzip_dir, 'Brain_Stroke_CT-SCAN_image 2')
train_dir = os.path.join(data_dir, 'Train')
test_dir = os.path.join(data_dir, 'Test')
val_dir = os.path.join(data_dir,'Validation')

def load_dataset(directory):
    images = []
    labels = []
    for label in os.listdir(directory):
        label_dir = os.path.join(directory, label)
        if not os.path.isdir(label_dir):
            continue
        for image_file in os.listdir(label_dir):
            image_path = os.path.join(label_dir, image_file)
            if not image_file.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):
                continue
            image = cv2.imread(image_path)
            image = cv2.resize(image, (128, 128))
            images.append(image)
            labels.append(label)
    return np.array(images), np.array(labels)

x_train, y_train = load_dataset(train_dir)
x_test, y_test = load_dataset(test_dir)
x_val, y_val = load_dataset(val_dir)

x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0
x_val = x_val.astype('float32') / 255.0

label_encoder = LabelEncoder()
y_train = label_encoder.fit_transform(y_train)
y_test = label_encoder.transform(y_test)
y_val = label_encoder.transform(y_val)

print('x_train shape:', x_train.shape)
print('x_test shape:', x_test.shape)
print('x_val shape:', x_val.shape)

for index, class_name in enumerate(label_encoder.classes_):
    print(f'Encoded label: {index} -> Class: {class_name}')

cnn = Sequential()
cnn.add(Conv2D(8, (3, 3), activation='relu', input_shape=(128, 128, 3), kernel_regularizer=l2(0.01)))
cnn.add(MaxPooling2D((2, 2)))

cnn.add(Conv2D(32, (3, 3), activation='relu'))
cnn.add(BatchNormalization())
cnn.add(MaxPooling2D((2, 2)))

cnn.add(Conv2D(64, (3, 3), activation='relu'))
cnn.add(MaxPooling2D((2, 2)))

cnn.add(Conv2D(64, (3, 3), activation='relu'))
cnn.add(BatchNormalization())
cnn.add(MaxPooling2D((2, 2)))

cnn.add(Flatten())
cnn.add(Dense(128, activation='relu'))
cnn.add(Dense(64, activation='relu'))
cnn.add(Dense(1, activation='sigmoid'))

cnn.summary()


cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
history_1 = cnn.fit(x_train,
                        y_train,
                        validation_data=(x_val, y_val),
                        epochs=20,
                        batch_size=32)


test_loss1, test_accuracy1 = cnn.evaluate(x_test, y_test)
print('Test Loss:', test_loss1)
print('Test Accuracy:', test_accuracy1)

cnn.save('brain_stroke_model.keras')
